{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import MLP\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOY DATASET (logic)\n",
    "\n",
    "Nous allons montrer la performance de notre implémentation du *Multi Layer Perceptron* grâce à deux exemples. \n",
    "\n",
    "D'abord, avec un *toy* dataset qui simule la logique (a and b or c). \n",
    "\n",
    "Ensuite, avec le dataset connu du *breast cancer*, où un score de test sera calculé pour démontrer le pouvoir de généralisation de notre MLP. \n",
    "\n",
    "Enfin, sur ce dernier exemple, nous comparons la performance de notre MLP avec celle d'une regression logistique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b, c\n",
    "# fn => (a and b) or c\n",
    "toy = [[1, 1, 1],  # true\n",
    "       [1, 0, 0],  # false\n",
    "       [0, 0, 0],  # false\n",
    "       [1, 0, 1],  # true\n",
    "       [1, 1, 0],  # true\n",
    "       [0, 0, 1],  # true\n",
    "       [0, 1, 1], # true\n",
    "       ]\n",
    "y = [\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1\n",
    "]\n",
    "X = pd.DataFrame(toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# SUMMARY : MultiLayerPercetron with architecture : [3, 3, 5, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "mlp = MLP.MutiLayerPerceptron(X, [3, 5, 3, 2, 1]) # 3 features a,b,c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le réseau MLP est maintenant crée. \n",
    "\n",
    "La classe comporte des méthodes pour montrer les Neuronnes par couche ainsi que les connexions (synapses) existantes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Montrer les Neuronnes**\n",
    "\n",
    "Nous pouvons voir: \n",
    "- Les Neuronnes par couche, avec leurs index (*i*,*j*)\n",
    "- Les Synapses auxquelles chaque neuronne appartient (*in* ou *out*)\n",
    "\n",
    "Enfin, nous voyons aussi que les poids ont été aléatoirement initialisés entre -1 et 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will see that none of the Nodes in Layer 0 is the output node of a synapse (No previous synapses)\n",
      "\n",
      "\n",
      "We will see that none of the Nodes in the last layer is the input to further synapses (No further synapses)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Connected Neurons layer 0\n",
      "Node Neuron00(-0.1) is in for  Synapse from Neuron00(-0.1) to Neuron10(0.4)\n",
      "Node Neuron00(-0.1) is in for  Synapse from Neuron00(-0.1) to Neuron11(0.6)\n",
      "Node Neuron00(-0.1) is in for  Synapse from Neuron00(-0.1) to Neuron12(0.0)\n",
      "Node Neuron01(0.9) is in for  Synapse from Neuron01(0.9) to Neuron10(0.4)\n",
      "Node Neuron01(0.9) is in for  Synapse from Neuron01(0.9) to Neuron11(0.6)\n",
      "Node Neuron01(0.9) is in for  Synapse from Neuron01(0.9) to Neuron12(0.0)\n",
      "Node Neuron02(0.6) is in for  Synapse from Neuron02(0.6) to Neuron10(0.4)\n",
      "Node Neuron02(0.6) is in for  Synapse from Neuron02(0.6) to Neuron11(0.6)\n",
      "Node Neuron02(0.6) is in for  Synapse from Neuron02(0.6) to Neuron12(0.0)\n",
      "\n",
      "\n",
      "Connected Neurons layer 1\n",
      "Node Neuron10(0.4) is in for  Synapse from Neuron10(0.4) to Neuron20(-0.9)\n",
      "Node Neuron10(0.4) is in for  Synapse from Neuron10(0.4) to Neuron21(-0.5)\n",
      "Node Neuron10(0.4) is in for  Synapse from Neuron10(0.4) to Neuron22(0.6)\n",
      "Node Neuron10(0.4) is in for  Synapse from Neuron10(0.4) to Neuron23(0.9)\n",
      "Node Neuron10(0.4) is in for  Synapse from Neuron10(0.4) to Neuron24(0.6)\n",
      "Node Neuron11(0.6) is in for  Synapse from Neuron11(0.6) to Neuron20(-0.9)\n",
      "Node Neuron11(0.6) is in for  Synapse from Neuron11(0.6) to Neuron21(-0.5)\n",
      "Node Neuron11(0.6) is in for  Synapse from Neuron11(0.6) to Neuron22(0.6)\n",
      "Node Neuron11(0.6) is in for  Synapse from Neuron11(0.6) to Neuron23(0.9)\n",
      "Node Neuron11(0.6) is in for  Synapse from Neuron11(0.6) to Neuron24(0.6)\n",
      "Node Neuron12(0.0) is in for  Synapse from Neuron12(0.0) to Neuron20(-0.9)\n",
      "Node Neuron12(0.0) is in for  Synapse from Neuron12(0.0) to Neuron21(-0.5)\n",
      "Node Neuron12(0.0) is in for  Synapse from Neuron12(0.0) to Neuron22(0.6)\n",
      "Node Neuron12(0.0) is in for  Synapse from Neuron12(0.0) to Neuron23(0.9)\n",
      "Node Neuron12(0.0) is in for  Synapse from Neuron12(0.0) to Neuron24(0.6)\n",
      "Node Neuron10(0.4) is out for Synapse from Neuron00(-0.1) to Neuron10(0.4)\n",
      "Node Neuron10(0.4) is out for Synapse from Neuron01(0.9) to Neuron10(0.4)\n",
      "Node Neuron10(0.4) is out for Synapse from Neuron02(0.6) to Neuron10(0.4)\n",
      "Node Neuron11(0.6) is out for Synapse from Neuron00(-0.1) to Neuron11(0.6)\n",
      "Node Neuron11(0.6) is out for Synapse from Neuron01(0.9) to Neuron11(0.6)\n",
      "Node Neuron11(0.6) is out for Synapse from Neuron02(0.6) to Neuron11(0.6)\n",
      "Node Neuron12(0.0) is out for Synapse from Neuron00(-0.1) to Neuron12(0.0)\n",
      "Node Neuron12(0.0) is out for Synapse from Neuron01(0.9) to Neuron12(0.0)\n",
      "Node Neuron12(0.0) is out for Synapse from Neuron02(0.6) to Neuron12(0.0)\n",
      "\n",
      "\n",
      "Connected Neurons layer 2\n",
      "Node Neuron20(-0.9) is in for  Synapse from Neuron20(-0.9) to Neuron30(0.6)\n",
      "Node Neuron20(-0.9) is in for  Synapse from Neuron20(-0.9) to Neuron31(-0.3)\n",
      "Node Neuron20(-0.9) is in for  Synapse from Neuron20(-0.9) to Neuron32(0.1)\n",
      "Node Neuron21(-0.5) is in for  Synapse from Neuron21(-0.5) to Neuron30(0.6)\n",
      "Node Neuron21(-0.5) is in for  Synapse from Neuron21(-0.5) to Neuron31(-0.3)\n",
      "Node Neuron21(-0.5) is in for  Synapse from Neuron21(-0.5) to Neuron32(0.1)\n",
      "Node Neuron22(0.6) is in for  Synapse from Neuron22(0.6) to Neuron30(0.6)\n",
      "Node Neuron22(0.6) is in for  Synapse from Neuron22(0.6) to Neuron31(-0.3)\n",
      "Node Neuron22(0.6) is in for  Synapse from Neuron22(0.6) to Neuron32(0.1)\n",
      "Node Neuron23(0.9) is in for  Synapse from Neuron23(0.9) to Neuron30(0.6)\n",
      "Node Neuron23(0.9) is in for  Synapse from Neuron23(0.9) to Neuron31(-0.3)\n",
      "Node Neuron23(0.9) is in for  Synapse from Neuron23(0.9) to Neuron32(0.1)\n",
      "Node Neuron24(0.6) is in for  Synapse from Neuron24(0.6) to Neuron30(0.6)\n",
      "Node Neuron24(0.6) is in for  Synapse from Neuron24(0.6) to Neuron31(-0.3)\n",
      "Node Neuron24(0.6) is in for  Synapse from Neuron24(0.6) to Neuron32(0.1)\n",
      "Node Neuron20(-0.9) is out for Synapse from Neuron10(0.4) to Neuron20(-0.9)\n",
      "Node Neuron20(-0.9) is out for Synapse from Neuron11(0.6) to Neuron20(-0.9)\n",
      "Node Neuron20(-0.9) is out for Synapse from Neuron12(0.0) to Neuron20(-0.9)\n",
      "Node Neuron21(-0.5) is out for Synapse from Neuron10(0.4) to Neuron21(-0.5)\n",
      "Node Neuron21(-0.5) is out for Synapse from Neuron11(0.6) to Neuron21(-0.5)\n",
      "Node Neuron21(-0.5) is out for Synapse from Neuron12(0.0) to Neuron21(-0.5)\n",
      "Node Neuron22(0.6) is out for Synapse from Neuron10(0.4) to Neuron22(0.6)\n",
      "Node Neuron22(0.6) is out for Synapse from Neuron11(0.6) to Neuron22(0.6)\n",
      "Node Neuron22(0.6) is out for Synapse from Neuron12(0.0) to Neuron22(0.6)\n",
      "Node Neuron23(0.9) is out for Synapse from Neuron10(0.4) to Neuron23(0.9)\n",
      "Node Neuron23(0.9) is out for Synapse from Neuron11(0.6) to Neuron23(0.9)\n",
      "Node Neuron23(0.9) is out for Synapse from Neuron12(0.0) to Neuron23(0.9)\n",
      "Node Neuron24(0.6) is out for Synapse from Neuron10(0.4) to Neuron24(0.6)\n",
      "Node Neuron24(0.6) is out for Synapse from Neuron11(0.6) to Neuron24(0.6)\n",
      "Node Neuron24(0.6) is out for Synapse from Neuron12(0.0) to Neuron24(0.6)\n",
      "\n",
      "\n",
      "Connected Neurons layer 3\n",
      "Node Neuron30(0.6) is in for  Synapse from Neuron30(0.6) to Neuron40(0.6)\n",
      "Node Neuron30(0.6) is in for  Synapse from Neuron30(0.6) to Neuron41(0.9)\n",
      "Node Neuron31(-0.3) is in for  Synapse from Neuron31(-0.3) to Neuron40(0.6)\n",
      "Node Neuron31(-0.3) is in for  Synapse from Neuron31(-0.3) to Neuron41(0.9)\n",
      "Node Neuron32(0.1) is in for  Synapse from Neuron32(0.1) to Neuron40(0.6)\n",
      "Node Neuron32(0.1) is in for  Synapse from Neuron32(0.1) to Neuron41(0.9)\n",
      "Node Neuron30(0.6) is out for Synapse from Neuron20(-0.9) to Neuron30(0.6)\n",
      "Node Neuron30(0.6) is out for Synapse from Neuron21(-0.5) to Neuron30(0.6)\n",
      "Node Neuron30(0.6) is out for Synapse from Neuron22(0.6) to Neuron30(0.6)\n",
      "Node Neuron30(0.6) is out for Synapse from Neuron23(0.9) to Neuron30(0.6)\n",
      "Node Neuron30(0.6) is out for Synapse from Neuron24(0.6) to Neuron30(0.6)\n",
      "Node Neuron31(-0.3) is out for Synapse from Neuron20(-0.9) to Neuron31(-0.3)\n",
      "Node Neuron31(-0.3) is out for Synapse from Neuron21(-0.5) to Neuron31(-0.3)\n",
      "Node Neuron31(-0.3) is out for Synapse from Neuron22(0.6) to Neuron31(-0.3)\n",
      "Node Neuron31(-0.3) is out for Synapse from Neuron23(0.9) to Neuron31(-0.3)\n",
      "Node Neuron31(-0.3) is out for Synapse from Neuron24(0.6) to Neuron31(-0.3)\n",
      "Node Neuron32(0.1) is out for Synapse from Neuron20(-0.9) to Neuron32(0.1)\n",
      "Node Neuron32(0.1) is out for Synapse from Neuron21(-0.5) to Neuron32(0.1)\n",
      "Node Neuron32(0.1) is out for Synapse from Neuron22(0.6) to Neuron32(0.1)\n",
      "Node Neuron32(0.1) is out for Synapse from Neuron23(0.9) to Neuron32(0.1)\n",
      "Node Neuron32(0.1) is out for Synapse from Neuron24(0.6) to Neuron32(0.1)\n",
      "\n",
      "\n",
      "Connected Neurons layer 4\n",
      "Node Neuron40(0.6) is in for  Synapse from Neuron40(0.6) to Neuron50(0.6)\n",
      "Node Neuron41(0.9) is in for  Synapse from Neuron41(0.9) to Neuron50(0.6)\n",
      "Node Neuron40(0.6) is out for Synapse from Neuron30(0.6) to Neuron40(0.6)\n",
      "Node Neuron40(0.6) is out for Synapse from Neuron31(-0.3) to Neuron40(0.6)\n",
      "Node Neuron40(0.6) is out for Synapse from Neuron32(0.1) to Neuron40(0.6)\n",
      "Node Neuron41(0.9) is out for Synapse from Neuron30(0.6) to Neuron41(0.9)\n",
      "Node Neuron41(0.9) is out for Synapse from Neuron31(-0.3) to Neuron41(0.9)\n",
      "Node Neuron41(0.9) is out for Synapse from Neuron32(0.1) to Neuron41(0.9)\n",
      "\n",
      "\n",
      "Connected Neurons layer 5\n",
      "Node Neuron50(0.6) is out for Synapse from Neuron40(0.6) to Neuron50(0.6)\n",
      "Node Neuron50(0.6) is out for Synapse from Neuron41(0.9) to Neuron50(0.6)\n"
     ]
    }
   ],
   "source": [
    "# PROVE NEURONS\n",
    "mlp.prove_neurons()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Montrer les Synapses**\n",
    "\n",
    "Les synapses connectent les neuronnes d'une couche à une autre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Connections layer 0 to 1\n",
      "Synapse from Neuron00(-0.1) to Neuron10(0.4)\n",
      "Synapse from Neuron01(0.9) to Neuron10(0.4)\n",
      "Synapse from Neuron02(0.6) to Neuron10(0.4)\n",
      "Synapse from Neuron00(-0.1) to Neuron11(0.6)\n",
      "Synapse from Neuron01(0.9) to Neuron11(0.6)\n",
      "Synapse from Neuron02(0.6) to Neuron11(0.6)\n",
      "Synapse from Neuron00(-0.1) to Neuron12(0.0)\n",
      "Synapse from Neuron01(0.9) to Neuron12(0.0)\n",
      "Synapse from Neuron02(0.6) to Neuron12(0.0)\n",
      "\n",
      "\n",
      "Connections layer 1 to 2\n",
      "Synapse from Neuron10(0.4) to Neuron20(-0.9)\n",
      "Synapse from Neuron11(0.6) to Neuron20(-0.9)\n",
      "Synapse from Neuron12(0.0) to Neuron20(-0.9)\n",
      "Synapse from Neuron10(0.4) to Neuron21(-0.5)\n",
      "Synapse from Neuron11(0.6) to Neuron21(-0.5)\n",
      "Synapse from Neuron12(0.0) to Neuron21(-0.5)\n",
      "Synapse from Neuron10(0.4) to Neuron22(0.6)\n",
      "Synapse from Neuron11(0.6) to Neuron22(0.6)\n",
      "Synapse from Neuron12(0.0) to Neuron22(0.6)\n",
      "Synapse from Neuron10(0.4) to Neuron23(0.9)\n",
      "Synapse from Neuron11(0.6) to Neuron23(0.9)\n",
      "Synapse from Neuron12(0.0) to Neuron23(0.9)\n",
      "Synapse from Neuron10(0.4) to Neuron24(0.6)\n",
      "Synapse from Neuron11(0.6) to Neuron24(0.6)\n",
      "Synapse from Neuron12(0.0) to Neuron24(0.6)\n",
      "\n",
      "\n",
      "Connections layer 2 to 3\n",
      "Synapse from Neuron20(-0.9) to Neuron30(0.6)\n",
      "Synapse from Neuron21(-0.5) to Neuron30(0.6)\n",
      "Synapse from Neuron22(0.6) to Neuron30(0.6)\n",
      "Synapse from Neuron23(0.9) to Neuron30(0.6)\n",
      "Synapse from Neuron24(0.6) to Neuron30(0.6)\n",
      "Synapse from Neuron20(-0.9) to Neuron31(-0.3)\n",
      "Synapse from Neuron21(-0.5) to Neuron31(-0.3)\n",
      "Synapse from Neuron22(0.6) to Neuron31(-0.3)\n",
      "Synapse from Neuron23(0.9) to Neuron31(-0.3)\n",
      "Synapse from Neuron24(0.6) to Neuron31(-0.3)\n",
      "Synapse from Neuron20(-0.9) to Neuron32(0.1)\n",
      "Synapse from Neuron21(-0.5) to Neuron32(0.1)\n",
      "Synapse from Neuron22(0.6) to Neuron32(0.1)\n",
      "Synapse from Neuron23(0.9) to Neuron32(0.1)\n",
      "Synapse from Neuron24(0.6) to Neuron32(0.1)\n",
      "\n",
      "\n",
      "Connections layer 3 to 4\n",
      "Synapse from Neuron30(0.6) to Neuron40(0.6)\n",
      "Synapse from Neuron31(-0.3) to Neuron40(0.6)\n",
      "Synapse from Neuron32(0.1) to Neuron40(0.6)\n",
      "Synapse from Neuron30(0.6) to Neuron41(0.9)\n",
      "Synapse from Neuron31(-0.3) to Neuron41(0.9)\n",
      "Synapse from Neuron32(0.1) to Neuron41(0.9)\n",
      "\n",
      "\n",
      "Connections layer 4 to 5\n",
      "Synapse from Neuron40(0.6) to Neuron50(0.6)\n",
      "Synapse from Neuron41(0.9) to Neuron50(0.6)\n"
     ]
    }
   ],
   "source": [
    "mlp.prove_synapses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement sur le Toy Dataset. \n",
    "\n",
    "Nous allons entraîner notre modèle avec le *toy* example du *and* suivi du *or*. \n",
    "La classe fait du \"Early stop\" toute seule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. line : 0 Pred : 1  Target : 1\n",
      "Epoch 0. line : 1 Pred : 1  Target : 0\n",
      "Epoch 0. line : 2 Pred : 0  Target : 0\n",
      "Epoch 0. line : 3 Pred : 0  Target : 1\n",
      "Epoch 0. line : 4 Pred : 1  Target : 1\n",
      "Epoch 0. line : 5 Pred : 0  Target : 1\n",
      "Epoch 0. line : 6 Pred : 1  Target : 1\n",
      "Epoch 0. Absolute Loss 0.42857142857142855. Accuracy 0.8571428571428571\n",
      "\n",
      "\n",
      "Epoch 1. line : 0 Pred : 1  Target : 1\n",
      "Epoch 1. line : 1 Pred : 1  Target : 0\n",
      "Epoch 1. line : 2 Pred : 0  Target : 0\n",
      "Epoch 1. line : 3 Pred : 0  Target : 1\n",
      "Epoch 1. line : 4 Pred : 1  Target : 1\n",
      "Epoch 1. line : 5 Pred : 1  Target : 1\n",
      "Epoch 1. line : 6 Pred : 1  Target : 1\n",
      "Epoch 1. Absolute Loss 0.2857142857142857. Accuracy 0.8571428571428571\n",
      "\n",
      "\n",
      "Epoch 2. line : 0 Pred : 1  Target : 1\n",
      "Epoch 2. line : 1 Pred : 1  Target : 0\n",
      "Epoch 2. line : 2 Pred : 0  Target : 0\n",
      "Epoch 2. line : 3 Pred : 0  Target : 1\n",
      "Epoch 2. line : 4 Pred : 1  Target : 1\n",
      "Epoch 2. line : 5 Pred : 1  Target : 1\n",
      "Epoch 2. line : 6 Pred : 1  Target : 1\n",
      "Epoch 2. Absolute Loss 0.2857142857142857. Accuracy 0.8571428571428571\n",
      "\n",
      "\n",
      "Epoch 3. line : 0 Pred : 1  Target : 1\n",
      "Epoch 3. line : 1 Pred : 0  Target : 0\n",
      "Epoch 3. line : 2 Pred : 0  Target : 0\n",
      "Epoch 3. line : 3 Pred : 0  Target : 1\n",
      "Epoch 3. line : 4 Pred : 1  Target : 1\n",
      "Epoch 3. line : 5 Pred : 1  Target : 1\n",
      "Epoch 3. line : 6 Pred : 1  Target : 1\n",
      "Epoch 3. Absolute Loss 0.14285714285714285. Accuracy 1.0\n",
      "\n",
      "\n",
      "Epoch 4. line : 0 Pred : 1  Target : 1\n",
      "Epoch 4. line : 1 Pred : 0  Target : 0\n",
      "Epoch 4. line : 2 Pred : 0  Target : 0\n",
      "Epoch 4. line : 3 Pred : 1  Target : 1\n",
      "Epoch 4. line : 4 Pred : 1  Target : 1\n",
      "Epoch 4. line : 5 Pred : 1  Target : 1\n",
      "Epoch 4. line : 6 Pred : 1  Target : 1\n",
      "Epoch 4. Absolute Loss 0.0. Accuracy 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = mlp.train(X,y, epochs=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir qu'après quelques *epochs*, le modèle ne fait plus d'érreurs. C'est à dire que la classe (1 ou 0) de chaque exemple est prédite correctement.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  BREAST CANCER TRAINING\n",
    "\n",
    "Ce dataset permet d'illuster à nouveau la classification binaire, mais cette fois-ci avec un exemple réel et plus conséquent (30 *features*, 569 *instances*).\n",
    "\n",
    "- 0 : Pas de cancer\n",
    "- 1: Cancer\n",
    "\n",
    "Le dataset comporte 30 colonnes pour l'entraînement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description du Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXRACT X AND Y\n",
    "X = pd.DataFrame(data[\"data\"])\n",
    "X.columns = data[\"feature_names\"]\n",
    "ys = data[\"target\"]\n",
    "\n",
    "# TRAIN TEST SPLIT\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, ys, random_state=1)\n",
    "X_train.reset_index(drop=True, inplace = True)\n",
    "X_test.reset_index(drop= True, inplace = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle pour le Brest Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# SUMMARY : MultiLayerPercetron with architecture : [30, 10, 10, 5, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "# MLP TRAINING \n",
    "# On peut voir qu'il y a 30 features\n",
    "mlp = MLP.MutiLayerPerceptron(pd.DataFrame(X_train), [10, 10, 5, 3, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Absolute Loss 0.568075117370892. Accuracy 0.3685446009389671\n",
      "Epoch 1. Absolute Loss 0.5492957746478874. Accuracy 0.3685446009389671\n",
      "Epoch 2. Absolute Loss 0.5258215962441315. Accuracy 0.6314553990610329\n",
      "Epoch 3. Absolute Loss 0.5234741784037559. Accuracy 0.6314553990610329\n",
      "Epoch 4. Absolute Loss 0.5305164319248826. Accuracy 0.6314553990610329\n",
      "Epoch 5. Absolute Loss 0.5328638497652582. Accuracy 0.6314553990610329\n",
      "Epoch 6. Absolute Loss 0.5164319248826291. Accuracy 0.6314553990610329\n",
      "Epoch 7. Absolute Loss 0.528169014084507. Accuracy 0.6314553990610329\n",
      "Epoch 8. Absolute Loss 0.5211267605633803. Accuracy 0.6314553990610329\n",
      "Epoch 9. Absolute Loss 0.5187793427230047. Accuracy 0.6314553990610329\n",
      "Epoch 10. Absolute Loss 0.5070422535211268. Accuracy 0.6314553990610329\n",
      "Epoch 11. Absolute Loss 0.5093896713615024. Accuracy 0.6314553990610329\n",
      "Epoch 12. Absolute Loss 0.5211267605633803. Accuracy 0.6314553990610329\n",
      "Epoch 13. Absolute Loss 0.5023474178403756. Accuracy 0.6314553990610329\n",
      "Epoch 14. Absolute Loss 0.5046948356807511. Accuracy 0.6314553990610329\n",
      "Epoch 15. Absolute Loss 0.49295774647887325. Accuracy 0.6314553990610329\n",
      "Epoch 16. Absolute Loss 0.5234741784037559. Accuracy 0.6314553990610329\n",
      "Epoch 17. Absolute Loss 0.5070422535211268. Accuracy 0.6314553990610329\n",
      "Epoch 18. Absolute Loss 0.5. Accuracy 0.6314553990610329\n",
      "Epoch 19. Absolute Loss 0.5070422535211268. Accuracy 0.6314553990610329\n",
      "Epoch 20. Absolute Loss 0.4788732394366197. Accuracy 0.6314553990610329\n",
      "Epoch 21. Absolute Loss 0.4953051643192488. Accuracy 0.6314553990610329\n",
      "Epoch 22. Absolute Loss 0.5070422535211268. Accuracy 0.6338028169014085\n",
      "Epoch 23. Absolute Loss 0.40375586854460094. Accuracy 0.8755868544600939\n",
      "Epoch 24. Absolute Loss 0.176056338028169. Accuracy 0.8943661971830986\n",
      "Epoch 25. Absolute Loss 0.176056338028169. Accuracy 0.8943661971830986\n",
      "Epoch 26. Absolute Loss 0.1784037558685446. Accuracy 0.8967136150234741\n",
      "Epoch 27. Absolute Loss 0.16901408450704225. Accuracy 0.8967136150234741\n",
      "Epoch 28. Absolute Loss 0.176056338028169. Accuracy 0.8990610328638498\n",
      "Epoch 29. Absolute Loss 0.17370892018779344. Accuracy 0.8967136150234741\n",
      "Epoch 30. Absolute Loss 0.176056338028169. Accuracy 0.8967136150234741\n",
      "Epoch 31. Absolute Loss 0.1784037558685446. Accuracy 0.8990610328638498\n",
      "Epoch 32. Absolute Loss 0.17136150234741784. Accuracy 0.8873239436619719\n",
      "Epoch 33. Absolute Loss 0.1784037558685446. Accuracy 0.8967136150234741\n",
      "Epoch 34. Absolute Loss 0.17136150234741784. Accuracy 0.8896713615023474\n",
      "Epoch 35. Absolute Loss 0.16901408450704225. Accuracy 0.8990610328638498\n",
      "Epoch 36. Absolute Loss 0.1643192488262911. Accuracy 0.8896713615023474\n",
      "Epoch 37. Absolute Loss 0.1619718309859155. Accuracy 0.8943661971830986\n",
      "Epoch 38. Absolute Loss 0.1619718309859155. Accuracy 0.8943661971830986\n",
      "Epoch 39. Absolute Loss 0.1619718309859155. Accuracy 0.8967136150234741\n",
      "Epoch 40. Absolute Loss 0.1596244131455399. Accuracy 0.8990610328638498\n",
      "Epoch 41. Absolute Loss 0.1572769953051643. Accuracy 0.8990610328638498\n",
      "Epoch 42. Absolute Loss 0.1619718309859155. Accuracy 0.9014084507042254\n",
      "Epoch 43. Absolute Loss 0.15258215962441316. Accuracy 0.8967136150234741\n",
      "Epoch 44. Absolute Loss 0.15492957746478872. Accuracy 0.8967136150234741\n",
      "Epoch 45. Absolute Loss 0.1619718309859155. Accuracy 0.8967136150234741\n",
      "Epoch 46. Absolute Loss 0.15258215962441316. Accuracy 0.8943661971830986\n",
      "Epoch 47. Absolute Loss 0.15492957746478872. Accuracy 0.8943661971830986\n",
      "Epoch 48. Absolute Loss 0.1596244131455399. Accuracy 0.8943661971830986\n",
      "Epoch 49. Absolute Loss 0.1596244131455399. Accuracy 0.8967136150234741\n",
      "Epoch 50. Absolute Loss 0.1572769953051643. Accuracy 0.8967136150234741\n",
      "Epoch 51. Absolute Loss 0.1572769953051643. Accuracy 0.8990610328638498\n",
      "Epoch 52. Absolute Loss 0.15492957746478872. Accuracy 0.8990610328638498\n",
      "Epoch 53. Absolute Loss 0.1596244131455399. Accuracy 0.8990610328638498\n",
      "Epoch 54. Absolute Loss 0.15492957746478872. Accuracy 0.8967136150234741\n",
      "Epoch 55. Absolute Loss 0.14553990610328638. Accuracy 0.8967136150234741\n",
      "Epoch 56. Absolute Loss 0.15258215962441316. Accuracy 0.9014084507042254\n",
      "Epoch 57. Absolute Loss 0.1431924882629108. Accuracy 0.8967136150234741\n",
      "Epoch 58. Absolute Loss 0.14553990610328638. Accuracy 0.8967136150234741\n",
      "Epoch 59. Absolute Loss 0.14788732394366197. Accuracy 0.9014084507042254\n",
      "Epoch 60. Absolute Loss 0.14084507042253522. Accuracy 0.8967136150234741\n",
      "Epoch 61. Absolute Loss 0.14553990610328638. Accuracy 0.8990610328638498\n",
      "Epoch 62. Absolute Loss 0.15258215962441316. Accuracy 0.8967136150234741\n",
      "Epoch 63. Absolute Loss 0.15258215962441316. Accuracy 0.8967136150234741\n",
      "Epoch 64. Absolute Loss 0.14788732394366197. Accuracy 0.8967136150234741\n",
      "Epoch 65. Absolute Loss 0.13380281690140844. Accuracy 0.9014084507042254\n",
      "Epoch 66. Absolute Loss 0.13615023474178403. Accuracy 0.8990610328638498\n",
      "Epoch 67. Absolute Loss 0.1431924882629108. Accuracy 0.8967136150234741\n",
      "Epoch 68. Absolute Loss 0.13849765258215962. Accuracy 0.9014084507042254\n",
      "Epoch 69. Absolute Loss 0.13380281690140844. Accuracy 0.8990610328638498\n"
     ]
    }
   ],
   "source": [
    "l = mlp.train(X_train,y_train, epochs=70, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION : Score pour des données jamais vues.\n",
    "\n",
    "Notre modèle MLP a obtenu un score d'*accuracy* très élevé pour les données de test (donc jamais vues). L'accuracy de *train* étant inférieur à celle de *test*, nous pouvons conclure qu'il n'y a pas eu d'*overfitting*. \n",
    "\n",
    "Le modèle à donc un bon pouvoir de généralisation et la performace prédictive est très bonne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951048951048951"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = mlp.predict(X_test)\n",
    "accuracy_score(y_test, y_test_pred) ## Very good accuracy score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparaison avec un modèle classique.\n",
    "\n",
    "La performace de notre modèle est comparable à celle du classificateur logistique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=1, max_iter=10000).fit(X_train, y_train)\n",
    "y_test_pred_logistic = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_test_pred_logistic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
